# -*- coding: utf-8 -*-
"""nlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dSKip2-cQDJOxvFq_9AgMqGbEFE81Vr9

The objective of the project was to perform sentiment analysis on customer reviews for an e-commerce platform. The goal was to develop machine learning models that could accurately classify reviews as positive, negative, or neutral.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import string
# %matplotlib inline

df = pd.read_csv('retail.csv')
df.head()

df.isnull().sum() # finding null value

df.dropna(inplace=True)# null value fillup
null_values = df.isnull().sum()
null_values

sns.countplot(data=df, y='Rate', order=df.Rate.value_counts().index)

df = df[(df.Rate !='Pigeon Favourite Electric Kettle??????(1.5 L, Silver, Black)') & (df.Rate != "Bajaj DX 2 L/W Dry Iron") & (df.Rate !='Nova Plus Amaze NI 10 1100 W Dry Iron?ÃÂ¿?ÃÂ¿(Grey & Turquoise)')]

sns.countplot(data=df, x='Rate', order=df.Rate.value_counts().index)

sns.countplot(data=df, x='Sentiment', order=df.Sentiment.value_counts().index)

"""text classification"""

import nltk
nltk.download('punkt')
nltk.download("stopwords")
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

stop_words = set(stopwords.words('english'))

df['Product_review'] = df['Product_review'].apply(lambda x: x.lower())
df['Product_review'] = df['Product_review'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))

def preprocess_text(text):

    tokens = word_tokenize(text.lower()) #text ko token ki form
                                         #remove punctuation and stop words
    filtered_tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]
    preprocessed_text = ' '.join(filtered_tokens) #  filtered tokens into a string ko again rejoin
    return preprocessed_text
df['preprocessed_P_review'] = df['Product_review'].apply(preprocess_text)#product review column preprocessed

df['preprocessed_P_review']

#Converting text into Vectors(number of times in the text a word appears)
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()

#count vectorization
preprocess_review = cv.fit_transform(df['Product_review']) #x independent
y = df['Sentiment']

"""machine learning classifier"""

#Model training, Evaluation, and Prediction
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(preprocess_review, y, test_size=0.2, random_state=42)

#first model naive bayes
#This classifier makes use of a multinomial distribution and is often used to solve issues involving document or text classification.
from sklearn.naive_bayes import MultinomialNB
nb = MultinomialNB()
nb.fit(X_train,y_train)

#testing the model
from sklearn.metrics import classification_report,accuracy_score
prediction = nb.predict(X_test) # predictions on the test set
print(classification_report(y_test,prediction))

prediction = nb.predict(X_test)
print(accuracy_score(y_test,prediction)) #naive bayes accuray

#decision tree 2 model
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(X_train,y_train)

prediction = dt.predict(X_test) # predictions on the test set
print(classification_report(y_test,prediction))

prediction = dt.predict(X_test)
print(accuracy_score(y_test,prediction))#accuracy dt

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train,y_train)

prediction = rf.predict(X_test) # predictions on the test set
print(classification_report(y_test,prediction))

prediction = rf.predict(X_test)
print(accuracy_score(y_test,prediction))

! pip install --user scipy wordcloud nltk seaborn textblob